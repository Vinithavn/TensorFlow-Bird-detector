{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Bird_detector1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/raspberry_pi"
      ],
      "metadata": {
        "id": "9mddJWm16XCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.1 "
      ],
      "metadata": {
        "id": "9zz0xnnV3vTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyLOgolxuzWk"
      },
      "outputs": [],
      "source": [
        "!pip install tflite-support==0.4.0 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE='./efficientdet_lite0.tflite'  "
      ],
      "metadata": {
        "id": "E7M7e0P6ykNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \\\n",
        "    -L 'https://tfhub.dev/tensorflow/lite-model/efficientdet/lite0/detection/metadata/1?lite-format=tflite' -o {FILE}"
      ],
      "metadata": {
        "id": "_NHt9pZZxUeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libportaudio2\n",
        "!pip install sounddevice"
      ],
      "metadata": {
        "id": "7nKts6mOzWY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pushbullet.py==0.9.1\n",
        "!pip install pywebio "
      ],
      "metadata": {
        "id": "Af7f3kuo8U2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pushbullet import PushBullet\n",
        "from pywebio.input import *\n",
        "from pywebio.output import *\n",
        "from pywebio.session import *\n",
        "import time "
      ],
      "metadata": {
        "id": "GvFhVbo98lQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the following modules\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Function to send Push Notification\n",
        "\n",
        "\n",
        "def pushbullet_noti(title, body):\n",
        "\n",
        "\tTOKEN = '' # Pass your Access Token here\n",
        "\t# Make a dictionary that includes, title and body\n",
        "\tmsg = {\"type\": \"note\", \"title\": title, \"body\": body}\n",
        "\t# Sent a posts request\n",
        "\tresp = requests.post('https://api.pushbullet.com/v2/pushes',\n",
        "\t\t\t\t\t\tdata=json.dumps(msg),\n",
        "\t\t\t\t\t\theaders={'Authorization': 'Bearer ' + TOKEN,\n",
        "\t\t\t\t\t\t\t\t'Content-Type': 'application/json'})\n",
        "\tif resp.status_code != 200: \n",
        "\t\traise Exception('Error', resp.status_code)\n",
        "\telse:\n",
        "\t\tprint('Message sent')\n"
      ],
      "metadata": {
        "id": "1FGCr3t_8zuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import html\n",
        "import io\n",
        "import time\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data"
      ],
      "metadata": {
        "id": "hXj_A5Pl6Lja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def js_reply_to_image(js_reply):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          js_reply: JavaScript object, contain image from webcam\n",
        "\n",
        "    output: \n",
        "          image_array: image array RGB size 512 x 512 from webcam\n",
        "    \"\"\"\n",
        "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\n",
        "    image_array = np.array(image_PIL)\n",
        "\n",
        "    return image_array"
      ],
      "metadata": {
        "id": "xSZDCktP6LmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import argparse\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "from tflite_support.task import core\n",
        "from tflite_support.task import processor\n",
        "from tflite_support.task import vision"
      ],
      "metadata": {
        "id": "5rp_7FloyfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_margin = 10 \n",
        "_row=10\n",
        "_font_size=1\n",
        "_font_thickness =1\n",
        "_text_color=(0,0,255)"
      ],
      "metadata": {
        "id": "pv_4WjlgzIWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(image:np.ndarray,detection_result:processor.DetectionResult):\n",
        "  '''\n",
        "    Draws bounding boxes on the detection results and returns it\n",
        "    Inputs - input image, detection entities to visualize\n",
        "    Output-Image with bounding box\n",
        "  '''\n",
        "  for detection in detection_result.detections:\n",
        "    #draw the bounding box\n",
        "    bbox = detection.bounding_box\n",
        "    start_point = bbox.origin_x,bbox.origin_y\n",
        "    end_point = bbox.origin_x+bbox.width, bbox.origin_y+bbox.height\n",
        "    cv2.rectangle(image,start_point,end_point,_text_color,3)\n",
        "    #print the label\n",
        "    category = detection.classes[0]\n",
        "    class_name = category.class_name\n",
        "    probability = round(category.score,2)\n",
        "    result_text = class_name + \" \" +str(probability*100)+ \"%\"\n",
        "    text_location = (_margin+bbox.origin_x , _margin+_row+bbox.origin_y)\n",
        "    cv2.putText(image, result_text,text_location,cv2.FONT_HERSHEY_PLAIN, _font_size,_text_color,_font_thickness)\n",
        "\n",
        "  return image\n"
      ],
      "metadata": {
        "id": "XcpU0Unsztlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime \n",
        "import time"
      ],
      "metadata": {
        "id": "pL7EoBdehlFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(model: str, num_threads: int,\n",
        "        enable_edgetpu: bool):\n",
        "  '''\n",
        "  Continuously run the inference on the images from the camera\n",
        "  Inputs- \n",
        "    model-name of the tflite pbject detection model\n",
        "    cameraid-id of the camera\n",
        "    width-width of the frame captured in the video\n",
        "    height- height of the frame captured\n",
        "    num_threads-No of cpus to run the model\n",
        "    enable_tpu - whether or not to enable the edge TPU \n",
        "  '''\n",
        "  row_size = 20  # pixels\n",
        "  left_margin = 24  # pixels\n",
        "  text_color = (0, 0, 255)  # red\n",
        "  font_size = 1\n",
        "  font_thickness = 1\n",
        "  fps_avg_frame_count = 10\n",
        "\n",
        "  # Initialize the object detection model\n",
        "  base_options = core.BaseOptions(\n",
        "        file_name=model, use_coral=enable_edgetpu, num_threads=num_threads)\n",
        "  detection_options = processor.DetectionOptions(\n",
        "        max_results=3, score_threshold=0.3)\n",
        "  options = vision.ObjectDetectorOptions(\n",
        "        base_options=base_options, detection_options=detection_options)\n",
        "  detector = vision.ObjectDetector.create_from_options(options)\n",
        "\n",
        "  \n",
        "\n",
        "  start_input()\n",
        "  label_html = 'Capturing...'\n",
        "  img_data = ''\n",
        "  count = 0 \n",
        "  fri=0 \n",
        "  result = cv2.VideoWriter('output.mp4', \n",
        "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
        "                         1, (512,512))\n",
        "  while True:\n",
        "    js_reply = take_photo(label_html, img_data)\n",
        "    if not js_reply:\n",
        "      break\n",
        "    image = js_reply_to_image(js_reply)\n",
        "    width,height,_ = image.shape\n",
        "    image = cv2.flip(image,1)\n",
        "\n",
        "    \n",
        "    #convert the image from bgr to rgb if required\n",
        "    rgb_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    result.write(rgb_image)\n",
        "    #create a tensor image object\n",
        "    input_tensor = vision.TensorImage.create_from_array(rgb_image)\n",
        "    detection_result = detector.detect(input_tensor)\n",
        "    for detect in (detection_result).detections:\n",
        "      if detect.classes[0].class_name == \"bird\":\n",
        "        fri+=1\n",
        "        if fri==1:\n",
        "          c_time = time.time() \n",
        "          print(\"Bird identified\")\n",
        "          pushbullet_noti(\"Alert\", \"A bird detected\")\n",
        "        else:\n",
        "          diff =  time.time()-c_time \n",
        "          # print(diff)\n",
        "          if diff>10:\n",
        "            print(\"Bird identified\")\n",
        "            pushbullet_noti(\"Alert\", \"A bird detected\")\n",
        "            fri=0\n",
        "      \n",
        "        \n",
        "    image = visualize(image, detection_result) \n",
        "    \n",
        "    # plt.imshow(image) \n",
        "    # plt.show()\n",
        "    if not js_reply:\n",
        "        break\n",
        "  # video.release()\n",
        "  result.release()\n",
        "    \n",
        "  "
      ],
      "metadata": {
        "id": "KjeQ2RXX7QyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'efficientdet_lite0.tflite'\n",
        "num_threads = 1\n",
        "enable_edgetpu = False\n",
        "run(model,num_threads,enable_edgetpu)\n",
        "\n"
      ],
      "metadata": {
        "id": "mpo6Vuij6s5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eGHK9bk2Yb4J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}